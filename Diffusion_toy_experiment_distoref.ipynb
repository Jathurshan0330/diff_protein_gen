{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8094e0c-ff04-4fb0-8d81-84c248f47f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"],torch.cuda.device_count(), torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b6c8be6-f95d-4d49-89f7-5f9770665211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu102\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "# from utils import *\n",
    "# from modules import UNet\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch import optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import time\n",
    "import math\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.cuda.is_available()\n",
    "\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e256dc1-8ad0-41b7-9fbc-58bc72cdd62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion:\n",
    "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=[32, 16, 16], device=\"cuda\"):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.img_size = img_size\n",
    "        self.device = device\n",
    "\n",
    "        self.beta = self.prepare_noise_schedule().to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "\n",
    "    def prepare_noise_schedule(self):\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
    "\n",
    "    def noise_images(self, x, t):\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "        Ɛ = torch.randn_like(x)\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Ɛ, Ɛ\n",
    "\n",
    "    def sample_timesteps(self, n):\n",
    "        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
    "\n",
    "    def sample(self, model, n):\n",
    "        logging.info(f\"Sampling {n} new images....\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((n, self.img_size[0], self.img_size[1],self.img_size[2])).to(self.device)\n",
    "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
    "                t = (torch.ones(n) * i).long().to(self.device)\n",
    "                predicted_noise = model(x, t)\n",
    "                alpha = self.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.beta[t][:, None, None, None]\n",
    "                if i > 1:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        model.train()\n",
    "        # x = (x.clamp(-1, 1) + 1) / 2\n",
    "        # x = x.clamp(min=0)\n",
    "        # x = (x * 255).type(torch.uint8)\n",
    "        return x\n",
    "    \n",
    "    # def sample(self, model, n, labels, cfg_scale=3):\n",
    "    #     logging.info(f\"Sampling {n} new images....\")\n",
    "    #     model.eval()\n",
    "    #     with torch.no_grad():\n",
    "    #         x = torch.randn((n, self.img_size[0], self.img_size[1],self.img_size[2])).to(self.device)\n",
    "    #         for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
    "    #             t = (torch.ones(n) * i).long().to(self.device)\n",
    "    #             predicted_noise = model(x, t, labels)\n",
    "    #             if cfg_scale > 0:\n",
    "    #                 uncond_predicted_noise = model(x, t, None)\n",
    "    #                 predicted_noise = torch.lerp(uncond_predicted_noise, predicted_noise, cfg_scale)\n",
    "    #             alpha = self.alpha[t][:, None, None, None]\n",
    "    #             alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "    #             beta = self.beta[t][:, None, None, None]\n",
    "    #             if i > 1:\n",
    "    #                 noise = torch.randn_like(x)\n",
    "    #             else:\n",
    "    #                 noise = torch.zeros_like(x)\n",
    "    #             x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "    #     model.train()\n",
    "    #     # x = (x.clamp(-1, 1) + 1) / 2\n",
    "    #     # x = (x * 255).type(torch.uint8)\n",
    "        # x = x.clamp(0, 1)\n",
    "    #     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70221c9-1bd6-47c6-920c-9d630dd35254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjathurshan_0330\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for usage information.\n",
      "\n",
      "\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for usage information.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter-jathurshan/diff_protein_gen/wandb/run-20230301_021706-v7hmfohr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jathurshan_0330/diff_protein_gen/runs/v7hmfohr\" target=\"_blank\">floral-sound-32</a></strong> to <a href=\"https://wandb.ai/jathurshan_0330/diff_protein_gen\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    }
   ],
   "source": [
    "is_wandb = True\n",
    "if is_wandb:\n",
    "    import wandb\n",
    "    wandb.init(project=\"diff_protein_gen\", entity=\"jathurshan_0330\")\n",
    "    wandb.run.name = \"Dist_binned_generation(Diffusion)_unconditional\"\n",
    "    wandb.run.save()\n",
    "    # \"Finetuning only classification head Ki67 using SIMCLR Pretrained Model\"\n",
    "    exp_path = f\"./model_checkpoints/{wandb.run.name}\"\n",
    "    if not os.path.exists(exp_path):\n",
    "        os.mkdir(exp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b7ca6-6580-490b-b96d-175577ef6765",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6efbba38-3994-4839-adbc-a47bca4d786e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7555\n",
      "4918\n",
      "0.0 227.59543138843227\n"
     ]
    }
   ],
   "source": [
    "file_list = glob.glob(\"/home/jupyter-jathurshan/Protein_extracted_data/*.h5\")\n",
    "file_list.sort()\n",
    "print(len(file_list))\n",
    "\n",
    "\n",
    "new_list = []\n",
    "for i in file_list:\n",
    "    with h5py.File(i, \"r\") as f:\n",
    "            # dist_ref = np.array(f.get('dist_ref'))\n",
    "            sse = np.array(f.get('sse'))\n",
    "            # seq = np.array(f.get('seq'))\n",
    "            # mask = np.array(f.get('mask'))\n",
    "            f.close()\n",
    "    if len(sse.shape)!=0:\n",
    "        if sse.shape[-1]!=0:\n",
    "            new_list.append(i)\n",
    "print(len(new_list))#,error_list)\n",
    "\n",
    "\n",
    "c = 0\n",
    "max_value = 0\n",
    "min_value = 100000\n",
    "\n",
    "for i in new_list:\n",
    "    with h5py.File(i, \"r\") as f:\n",
    "            dist_ref = np.expand_dims(np.array(f.get('dist_ref')),axis=0)\n",
    "    if dist_ref.max()>max_value:\n",
    "        max_value = dist_ref.max()\n",
    "    if dist_ref.min()<min_value:\n",
    "        min_value = dist_ref.min()\n",
    "print(min_value,max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a4b351-d802-4643-8048-4644fb63e1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3934 492 492\n"
     ]
    }
   ],
   "source": [
    "#15051\n",
    "file_list = new_list#glob.glob(\"/home/jupyter-jathurshan/Protein_extracted_data/*.h5\")\n",
    "# file_list.sort()\n",
    "# print(len(file_list))\n",
    "\n",
    "train_file_list = file_list[:int(len(file_list)*0.8)]\n",
    "val_file_list = file_list[int(len(file_list)*0.8):int(len(file_list)*0.9)]\n",
    "test_file_list = file_list[int(len(file_list)*0.9):]\n",
    "\n",
    "print(len(train_file_list),len(val_file_list),len(test_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae364b80-ae98-4de7-a512-08358d45df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sub_plots(rows,columns,img_list,title_list,cmap = 'inferno'):\n",
    "    fig, axs = plt.subplots(rows, columns, figsize = (columns*10,rows*10))\n",
    "    if rows == 1:\n",
    "        for i in range(len(img_list)):\n",
    "            im1 = axs[i].imshow(img_list[i],cmap=cmap)\n",
    "            axs[i].set_title(f\"{title_list[i]}\")\n",
    "            plt.colorbar(im1, ax=axs[i])#,shrink = 0.3\n",
    "    else:\n",
    "        for i in range(len(img_list)):\n",
    "            im1 = axs[i//columns][i%columns].imshow(img_list[i],cmap=cmap)\n",
    "            axs[i//columns][i%columns].set_title(f\"{title_list[i]}\")\n",
    "            plt.colorbar(im1, ax=axs[i//columns][i%columns])#,shrink = 0.3)\n",
    "    # plt.show()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9596bcd7-f6b7-4790-9978-b1448de69760",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Disto ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a90348-5a4d-48c3-a9d4-0634d06eaac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# ### Using Distant Ref\n",
    "# class Protein_Dataset(Dataset):\n",
    "#     def __init__(self,file_list, device,pro_len = 64):\n",
    "      \n",
    "#         self.file_list = file_list\n",
    "#         self.pro_len = pro_len\n",
    "#         self.device = device\n",
    "        \n",
    "#         self.device = device\n",
    "        \n",
    "#         print(f\"Data_size : {len(self.file_list)}\") \n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.file_list )\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "        \n",
    "#         with h5py.File(self.file_list[idx], \"r\") as f:\n",
    "#             dist_ref = np.array(f.get('dist_ref'))\n",
    "#             dist_ref[np.isnan(dist_ref)] = 0\n",
    "#             sse = np.array(f.get('sse'))\n",
    "#             # seq = np.array(f.get('seq'))\n",
    "#             mask = np.array(f.get('mask'))\n",
    "#             f.close()\n",
    "        \n",
    "       \n",
    "        \n",
    "#         dist_ref = torch.from_numpy(dist_ref).unsqueeze(0).clamp(max=50)\n",
    "#         dist_ref =dist_ref/50\n",
    "#         sse = torch.from_numpy(sse).unsqueeze(0).float()\n",
    "#         # seq = np.array(f.get('seq'))\n",
    "#         mask = torch.from_numpy(mask).squeeze().unsqueeze(0)\n",
    "#         ref_len = dist_ref.shape[-1]\n",
    "#         # print(self.file_list[idx],dist_ref.shape,sse.shape)\n",
    "        \n",
    "#         # print(self.file_list[idx],dist_ref.shape,mask.shape,sse.shape)\n",
    "        \n",
    "# #         if dist_ref.shape[-1]<self.pro_len:\n",
    "# #             pad = ((self.pro_len-dist_ref.shape[-1])//2,(self.pro_len-dist_ref.shape[-1])//2,(self.pro_len-dist_ref.shape[-1])//2,(self.pro_len-dist_ref.shape[-1])//2)\n",
    "# #             dist_ref =  F.pad(dist_ref, pad, mode='reflect')\n",
    "# #             mask =  F.pad(mask, pad, mode='constant')\n",
    "            \n",
    "# #             pad = ((self.pro_len-sse.shape[-1])//2,(self.pro_len-sse.shape[-1])//2)\n",
    "# #             sse =  F.pad(sse, pad, mode='reflect')\n",
    "# #         elif dist_ref.shape[-1]>self.pro_len:\n",
    "# #             crop = transforms.CenterCrop(self.pro_len)\n",
    "# #             dist_ref = crop(dist_ref)\n",
    "# #             mask = crop(mask)\n",
    "# #             crop = transforms.CenterCrop((3,self.pro_len))\n",
    "# #             sse = crop(sse)\n",
    "         \n",
    "#         if dist_ref.shape[-1]!=self.pro_len:\n",
    "#             crop = transforms.CenterCrop(self.pro_len)\n",
    "#             dist_ref = crop(dist_ref)\n",
    "#             mask = crop(mask)\n",
    "#             crop = transforms.CenterCrop((3,self.pro_len))\n",
    "#             sse = crop(sse)\n",
    "           \n",
    "        \n",
    "# #         \n",
    "#         return dist_ref.to(self.device).float(), mask.to(self.device).float(), sse.to(self.device).float(),ref_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11da1eb-4384-4ed7-bfcc-65889f787d29",
   "metadata": {},
   "source": [
    "## Disto Binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60c341c-f8f0-4e90-ad4e-7a204b4b6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "### Using Distant binned\n",
    "def mtx2bins(x_ref, start, end, nbins, mask):\n",
    "    bins = np.linspace(start, end, nbins)\n",
    "    x_true = np.digitize(x_ref, bins).astype(np.uint8)\n",
    "    x_true[mask] = 0\n",
    "    return np.eye(nbins+1)[x_true][...,:-1]\n",
    "class Protein_Dataset(Dataset):\n",
    "    def __init__(self,file_list, device,pro_len = 64):\n",
    "      \n",
    "        self.file_list = file_list\n",
    "        self.pro_len = pro_len\n",
    "        self.device = device\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        print(f\"Data_size : {len(self.file_list)}\") \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        with h5py.File(self.file_list[idx], \"r\") as f:\n",
    "            dist_ref = np.array(f.get('dist_ref'))\n",
    "            dist_ref[np.isnan(dist_ref)] = 0\n",
    "            sse = np.array(f.get('sse'))\n",
    "            # seq = np.array(f.get('seq'))\n",
    "            mask = np.array(f.get('mask'))\n",
    "            f.close()\n",
    "        \n",
    "       \n",
    "        \n",
    "        # dist_ref = torch.from_numpy(dist_ref).unsqueeze(0)#.clamp(max=50)\n",
    "        # dist_ref =dist_ref/50\n",
    "        dist_ref  = torch.moveaxis(torch.from_numpy(mtx2bins(dist_ref,2.0,  20.0, 37, mask=(dist_ref > 20))),-1,0)\n",
    "        # print(dist_ref.shape)\n",
    "        sse = torch.from_numpy(sse).unsqueeze(0).float()\n",
    "        # seq = np.array(f.get('seq'))\n",
    "        mask = torch.from_numpy(mask).squeeze().unsqueeze(0)\n",
    "        ref_len = dist_ref.shape[-1]\n",
    "    \n",
    "         \n",
    "        if dist_ref.shape[-1]!=self.pro_len:\n",
    "            crop = transforms.CenterCrop(self.pro_len)\n",
    "            dist_ref = crop(dist_ref)\n",
    "            mask = crop(mask)\n",
    "            crop = transforms.CenterCrop((3,self.pro_len))\n",
    "            sse = crop(sse)\n",
    "           \n",
    "        \n",
    "#         \n",
    "        return dist_ref.to(self.device).float(), mask.to(self.device).float(), sse.to(self.device).float(),ref_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "672c935d-e085-4e56-8a15-ea4322806f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_size : 3934\n",
      "Data_size : 492\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Protein_Dataset(train_file_list, device = device) \n",
    "val_dataset = Protein_Dataset(val_file_list, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b251823-566a-4012-b9d0-2598f3a2a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "396cf7a7-d4fe-41d0-898b-b5eb457bd7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 37, 64, 64]) torch.Size([32, 1, 64, 64]) torch.Size([32, 1, 3, 64]) tensor([529, 207, 814, 357, 273, 125, 427, 229,  47, 207,  64, 291,  67, 170,\n",
      "        144, 191, 346, 119, 125, 178, 529,  74, 122, 112, 185, 265, 182, 210,\n",
      "        113, 180, 245, 328])\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_ref,mask,sse,ref_len   = next(iter(train_data_loader))\n",
    "\n",
    "print(dist_ref.shape,mask.shape,sse.shape,ref_len) \n",
    "ind = 0\n",
    "img_list = [dist_ref[ind].argmax(0).squeeze().detach().cpu().numpy(),\n",
    "           mask[ind].squeeze().detach().cpu().numpy(),\n",
    "           sse[ind].squeeze().detach().cpu().numpy(),\n",
    "           ]\n",
    "\n",
    "title_list = ['dist_ref','Mask','sse']\n",
    "plot_sub_plots(1,3,img_list,title_list,cmap = 'inferno')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1595d6c-e2eb-4964-8fc0-830b2f88e371",
   "metadata": {},
   "source": [
    "## Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1672a25-3732-4fed-8a7d-6e750afce067",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_nc=1, ngf = 16):\n",
    "        super(CNN_Encoder, self).__init__()\n",
    "        self.enc1 = self.enc_block(in_ch = input_nc, out_ch = ngf, kernel_size=4, stride=2, padding = 1,bias = True, innermost = False  )\n",
    "        self.enc2 = self.enc_block(in_ch = ngf, out_ch = ngf*2, kernel_size=4, stride=2, padding = 1,bias = True, innermost = False  )\n",
    "        # self.enc3 = self.enc_block(in_ch = ngf*2, out_ch = ngf*4, kernel_size=4, stride=2, padding = 1,bias = True, innermost = False  )\n",
    "        # self.enc4 = self.enc_block(in_ch = ngf*4, out_ch = ngf*8, kernel_size=4, stride=2, padding = 1,bias = True, innermost = False  )\n",
    "        # self.enc5 = self.enc_block(in_ch = ngf*8, out_ch = ngf*16, kernel_size=4, stride=2, padding = 1,bias = True, innermost = False  )\n",
    "        \n",
    "        \n",
    "    def enc_block(self, in_ch, out_ch, kernel_size=4, stride=2, padding = 1,bias = True, innermost = False):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size,stride=stride, padding=padding, bias=bias),\n",
    "                # nn.ReLU()\n",
    "                )\n",
    "      \n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.enc1(x)\n",
    "        x = self.enc2(x)\n",
    "        # x = self.enc3(x)\n",
    "        # x = self.enc4(x)\n",
    "        # x = self.enc5(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class CNN_Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, lat_chan=128,out_ch = 1, ngf = 16 ):\n",
    "        super(CNN_Decoder, self).__init__()\n",
    "        self.dec1 = self.conv_up_block(in_ch = lat_chan , out_ch = ngf*8, \n",
    "                                       kernel_size=4, stride=2, padding = 1,bias = True)\n",
    "        self.dec2 = self.conv_up_block(in_ch = ngf*8 , out_ch = out_ch, \n",
    "                                       kernel_size=4, stride=2, padding = 1,bias = True)\n",
    "        # self.dec3 = self.conv_up_block(in_ch = ngf*4 , out_ch = ngf*2, \n",
    "        #                                kernel_size=4, stride=2, padding = 1,bias = True)\n",
    "        # self.dec4 = self.conv_up_block(in_ch = ngf*2 , out_ch = 1, \n",
    "        #                                kernel_size=4, stride=2, padding = 1,bias = True)\n",
    "        # self.dec5 = self.conv_up_block(in_ch = ngf , out_ch = 1, \n",
    "                                       # kernel_size=4, stride=2, padding = 1,bias = True)\n",
    "        # self.final = nn.Linear(16,out_ch)\n",
    "        \n",
    "        \n",
    "    def conv_up_block(self,  in_ch, out_ch, kernel_size=4, stride=2, padding = 1,bias = True,outermost = False):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d( in_ch, out_ch, kernel_size=kernel_size, stride=stride, padding = padding,bias = bias),\n",
    "                # nn.ReLU()\n",
    "                )\n",
    "        \n",
    "    def forward(self,x): \n",
    "        x = self.dec1(x)\n",
    "        \n",
    "        x = self.dec2(x)\n",
    "        \n",
    "        \n",
    "#         x = self.dec3(x)\n",
    "        \n",
    "#         x = self.dec4(x)\n",
    "        # x = self.dec5(x)\n",
    "        # x = self.final(x)\n",
    "        # x = torch.moveaxis(x,-1,1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a1c9a0-6218-4535-8a18-974c4e40d09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17712\n",
      "141477\n"
     ]
    }
   ],
   "source": [
    "####Autoencoder Training Using Binned Distograms Masked loss\n",
    "enc_path = f'./model_checkpoints/Autoencoder Training Using Binned Distograms Masked loss/encoder_dist.pth.tar'\n",
    "\n",
    "### Disto ref autoencoder\n",
    "# enc_path = f'./model_checkpoints/Autoencoder Training Using Distoref/encoder_dist.pth.tar'\n",
    "encoder = torch.load(enc_path).to(device)#CNN_Encoder(ngf = 16).to(device)#torch.load(enc_path).to(device)\n",
    "encoder.eval()\n",
    "print(sum([np.prod(p.size()) for p in encoder.parameters()]))\n",
    "\n",
    "####Autoencoder Training Using Binned Distograms Masked loss\n",
    "dec_path = f'./model_checkpoints/Autoencoder Training Using Binned Distograms Masked loss/decoder_dist.pth.tar'\n",
    "### Disto ref autoencoder\n",
    "# dec_path = f'./model_checkpoints/Autoencoder Training Using Distoref/decoder_dist.pth.tar'\n",
    "decoder = torch.load(dec_path).to(device)#CNN_Decoder(lat_chan=32).to(device)#torch.load(dec_path).to(device)\n",
    "decoder.eval()\n",
    "print(sum([np.prod(p.size()) for p in decoder.parameters()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceda76a-cd41-4fab-bf3a-c436e39b7456",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b70d752f-24dc-409b-bf0b-902eb0f42d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.step = 0\n",
    "\n",
    "    def update_model_average(self, ma_model, current_model):\n",
    "        for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
    "            old_weight, up_weight = ma_params.data, current_params.data\n",
    "            ma_params.data = self.update_average(old_weight, up_weight)\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "\n",
    "    def step_ema(self, ema_model, model, step_start_ema=2000):\n",
    "        if self.step < step_start_ema:\n",
    "            self.reset_parameters(ema_model, model)\n",
    "            self.step += 1\n",
    "            return\n",
    "        self.update_model_average(ema_model, model)\n",
    "        self.step += 1\n",
    "\n",
    "    def reset_parameters(self, ema_model, model):\n",
    "        ema_model.load_state_dict(model.state_dict())\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, channels, size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.size = size\n",
    "        self.mha = nn.MultiheadAttention(channels, 4, batch_first=True)\n",
    "        self.ln = nn.LayerNorm([channels])\n",
    "        self.ff_self = nn.Sequential(\n",
    "            nn.LayerNorm([channels]),\n",
    "            nn.Linear(channels, channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels, channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.channels, self.size * self.size).swapaxes(1, 2)\n",
    "        x_ln = self.ln(x)\n",
    "        attention_value, _ = self.mha(x_ln, x_ln, x_ln)\n",
    "        attention_value = attention_value + x\n",
    "        attention_value = self.ff_self(attention_value) + attention_value\n",
    "        return attention_value.swapaxes(2, 1).view(-1, self.channels, self.size, self.size)\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None, residual=False):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, mid_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.residual:\n",
    "            return F.gelu(x + self.double_conv(x))\n",
    "        else:\n",
    "            return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim=256):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, in_channels, residual=True),\n",
    "            DoubleConv(in_channels, out_channels),\n",
    "        )\n",
    "\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_dim,\n",
    "                out_channels\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.maxpool_conv(x)\n",
    "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.conv = nn.Sequential(\n",
    "            DoubleConv(in_channels, in_channels, residual=True),\n",
    "            DoubleConv(in_channels, out_channels, in_channels // 2),\n",
    "        )\n",
    "\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_dim,\n",
    "                out_channels\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip_x, t):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([skip_x, x], dim=1)\n",
    "        x = self.conv(x)\n",
    "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, c_in=3, c_out=3, time_dim=256, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.time_dim = time_dim\n",
    "        self.inc = DoubleConv(c_in, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.sa1 = SelfAttention(128, 8)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.sa2 = SelfAttention(256, 4)\n",
    "        self.down3 = Down(256, 256)\n",
    "        self.sa3 = SelfAttention(256, 2)\n",
    "\n",
    "        self.bot1 = DoubleConv(256, 512)\n",
    "        self.bot2 = DoubleConv(512, 512)\n",
    "        self.bot3 = DoubleConv(512, 256)\n",
    "\n",
    "        self.up1 = Up(512, 128)\n",
    "        self.sa4 = SelfAttention(128, 4)\n",
    "        self.up2 = Up(256, 64)\n",
    "        self.sa5 = SelfAttention(64, 8)\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.sa6 = SelfAttention(64, 16)\n",
    "        self.outc = nn.Conv2d(64, c_out, kernel_size=1)\n",
    "\n",
    "    def pos_encoding(self, t, channels):\n",
    "        inv_freq = 1.0 / (\n",
    "            10000\n",
    "            ** (torch.arange(0, channels, 2, device=self.device).float() / channels)\n",
    "        )\n",
    "        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n",
    "        return pos_enc\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t = t.unsqueeze(-1).type(torch.float)\n",
    "        t = self.pos_encoding(t, self.time_dim)\n",
    "\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1, t)\n",
    "        # print(f\"x2: {x2.shape}\")\n",
    "        x2 = self.sa1(x2)\n",
    "        x3 = self.down2(x2, t)\n",
    "        # print(f\"x3: {x3.shape}\")\n",
    "        x3 = self.sa2(x3)\n",
    "        x4 = self.down3(x3, t)\n",
    "        # print(f\"x4: {x4.shape}\")\n",
    "        x4 = self.sa3(x4)\n",
    "        \n",
    "        # print(f\"x4: {x4.shape}\")\n",
    "        x4 = self.bot1(x4)\n",
    "        x4 = self.bot2(x4)\n",
    "        x4 = self.bot3(x4)\n",
    "        \n",
    "        # print(f\"x4: {x4.shape}\")\n",
    "        x = self.up1(x4, x3, t)\n",
    "        # print(f\"x: {x.shape}\")\n",
    "        x = self.sa4(x)\n",
    "        # print(f\"x: {x.shape}\")\n",
    "        x = self.up2(x, x2, t)\n",
    "        x = self.sa5(x)\n",
    "        x = self.up3(x, x1, t)\n",
    "        x = self.sa6(x)\n",
    "        output = self.outc(x)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class UNet_Conditional(nn.Module):\n",
    "    def __init__(self, c_in=3, c_out=3, time_dim=256, device=\"cuda\"):#,num_classes = None):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.time_dim = time_dim\n",
    "        self.inc = DoubleConv(c_in, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.sa1 = SelfAttention(128, 8)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.sa2 = SelfAttention(256, 4)\n",
    "        self.down3 = Down(256, 256)\n",
    "        self.sa3 = SelfAttention(256, 2)\n",
    "\n",
    "        self.bot1 = DoubleConv(256, 512)\n",
    "        self.bot2 = DoubleConv(512, 512)\n",
    "        self.bot3 = DoubleConv(512, 256)\n",
    "\n",
    "        self.up1 = Up(512, 128)\n",
    "        self.sa4 = SelfAttention(128, 4)\n",
    "        self.up2 = Up(256, 64)\n",
    "        self.sa5 = SelfAttention(64, 8)\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.sa6 = SelfAttention(64, 16)\n",
    "        self.outc = nn.Conv2d(64, c_out, kernel_size=1)\n",
    "        \n",
    "#         if num_classes is not None:\n",
    "#             self.label_emb = nn.Embedding(num_classes, time_dim)\n",
    "        \n",
    "\n",
    "    def pos_encoding(self, t, channels):\n",
    "        inv_freq = 1.0 / (\n",
    "            10000\n",
    "            ** (torch.arange(0, channels, 2, device=self.device).float() / channels)\n",
    "        )\n",
    "        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n",
    "        return pos_enc\n",
    "\n",
    "    def forward(self, x, t,labels):\n",
    "        t = t.unsqueeze(-1).type(torch.float)\n",
    "        t = self.pos_encoding(t, self.time_dim)\n",
    "        # print(f\"t:{t.shape}\")\n",
    "        if labels!=None:\n",
    "            # print(self.label_emb(labels).shape)\n",
    "            t = t+ labels\n",
    "        \n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1, t)\n",
    "        # print(f\"x2: {x2.shape}\")\n",
    "        x2 = self.sa1(x2)\n",
    "        x3 = self.down2(x2, t)\n",
    "        # print(f\"x3: {x3.shape}\")\n",
    "        x3 = self.sa2(x3)\n",
    "        x4 = self.down3(x3, t)\n",
    "        # print(f\"x4: {x4.shape}\")\n",
    "        x4 = self.sa3(x4)\n",
    "        \n",
    "        # print(f\"x4: {x4.shape}\")\n",
    "        x4 = self.bot1(x4)\n",
    "        x4 = self.bot2(x4)\n",
    "        x4 = self.bot3(x4)\n",
    "        \n",
    "        # print(f\"x4: {x4.shape}\")\n",
    "        x = self.up1(x4, x3, t)\n",
    "        # print(f\"x: {x.shape}\")\n",
    "        x = self.sa4(x)\n",
    "        # print(f\"x: {x.shape}\")\n",
    "        x = self.up2(x, x2, t)\n",
    "        x = self.sa5(x)\n",
    "        x = self.up3(x, x1, t)\n",
    "        x = self.sa6(x)\n",
    "        output = self.outc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6b0dc9e-1837-4a02-a7b5-3a6f9928667a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 16, 16]) torch.Size([32])\n",
      "torch.Size([32, 32, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "model = UNet(c_in=32, c_out=32, time_dim=256, device=\"cuda\").to(device)\n",
    "# cond_enc = Cond_Encoder().to(device)\n",
    "#testing\n",
    "dist_ref,mask,sse,ref_len   = next(iter(train_data_loader))\n",
    "# print(digit_labels.shape)\n",
    "\n",
    "lat_c = encoder(dist_ref)\n",
    "t = torch.randint(low=1, high=1000, size=(dist_ref.shape[0],)).to(device)\n",
    "# labels = encoder_sse(sse.squeeze(1))\n",
    "print(lat_c.shape,t.shape)#,labels.shape)\n",
    "\n",
    "denoised_lat_c = model(lat_c,t)\n",
    "\n",
    "print(denoised_lat_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4146e97f-ce5b-446c-aaad-6ea6b61cd4f7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea208cb-1715-4c8e-8f83-6bde0824a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.AdamW(list(model.parameters())+list(cond_enc.parameters()), lr=3e-4)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "mse = nn.MSELoss()\n",
    "diffusion = Diffusion(img_size=[32,16,16], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db363e4d-8974-43ac-848d-c44604ad4ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_loss(x_hat,x):\n",
    "    criterion = nn.L1Loss()\n",
    "    return criterion(x_hat,x)\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count if self.count != 0 else 0\n",
    "        \n",
    "def plot_sub_plots(rows,columns,img_list,title_list,cmap = 'inferno'):\n",
    "    fig, axs = plt.subplots(rows, columns, figsize = (columns*10,rows*10))\n",
    "    if rows == 1:\n",
    "        for i in range(len(img_list)):\n",
    "            im1 = axs[i].imshow(img_list[i],cmap=cmap)\n",
    "            axs[i].set_title(f\"{title_list[i]}\")\n",
    "            plt.colorbar(im1, ax=axs[i])#,shrink = 0.3\n",
    "    else:\n",
    "        for i in range(len(img_list)):\n",
    "            im1 = axs[i//columns][i%columns].imshow(img_list[i],cmap=cmap)\n",
    "            axs[i//columns][i%columns].set_title(f\"{title_list[i]}\")\n",
    "            plt.colorbar(im1, ax=axs[i//columns][i%columns])#,shrink = 0.3)\n",
    "    # plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3101d7f-4bac-4805-afdb-a39c3958159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,diffusion,encoder,decoder,optimizer,data_loader,is_wandb=False,verbose_freq = 500,is_verbose = False):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    model.train()\n",
    "    # cond_enc.train()\n",
    "    train_losses = AverageMeter()\n",
    "    for batch_idx, (x,m,sse,_ ) in enumerate(data_loader):\n",
    "        x = encoder(x)#*m)\n",
    "        \n",
    "        \n",
    "        t = diffusion.sample_timesteps(x.shape[0]).to(device)\n",
    "        x_t, noise = diffusion.noise_images(x, t)\n",
    "        predicted_noise = model(x_t, t)\n",
    "        \n",
    "        loss = mse(noise, predicted_noise) #+ recon_loss()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # break\n",
    "      \n",
    "        train_losses.update(loss.data.item())\n",
    "        if is_wandb:\n",
    "            wandb.log({\"batch_loss\": loss.data.item()})\n",
    "    \n",
    "    \n",
    "    if is_wandb:\n",
    "            wandb.log({\"train_epoch_loss\": train_losses.avg})\n",
    "            \n",
    "    if is_verbose:\n",
    "        print(f\"Training Epoch Loss: {train_losses.avg}\")\n",
    "    \n",
    "    x,m,sse,ref_len   = next(iter(data_loader))\n",
    "    # cond_enc.eval()\n",
    "    # digit_labels_2 = F.one_hot(digit_labels, num_classes=10).unsqueeze(1).float()\n",
    "    # cond_vec = cond_enc(digit_labels_2.to(device))\n",
    "    \n",
    "    sampled_images = diffusion.sample(model, n=x.shape[0])\n",
    "    sampled_images = decoder(sampled_images.float())#.clamp(min=0,max=1)\n",
    "    sampled_images = sampled_images.argmax(1).squeeze().detach().cpu().numpy()\n",
    "    print(sampled_images.shape)\n",
    "    sse = sse.squeeze().detach().cpu().numpy()\n",
    "    # img_list = [sampled_images[0],sse[0],sampled_images[1],sse[1],\n",
    "    #             sampled_images[2],sse[2],sampled_images[3],sse[3],\n",
    "    #             sampled_images[4],sse[4],sampled_images[5],sse[5],\n",
    "    #             sampled_images[6],sse[6],sampled_images[7],sse[7],\n",
    "    #            ] \n",
    "    \n",
    "    # title_list = [ref_len[0].item(),ref_len[0].item(),ref_len[1].item(),ref_len[1].item(),\n",
    "    #               ref_len[2].item(),ref_len[2].item(),ref_len[3].item(),ref_len[3].item(),\n",
    "    #               ref_len[4].item(),ref_len[4].item(),ref_len[5].item(),ref_len[5].item(),\n",
    "    #               ref_len[6].item(),ref_len[6].item(),ref_len[7].item(),ref_len[7].item(),]\n",
    "    \n",
    "    fig = plot_sub_plots(4,4,sampled_images[:16],[i for i in range (16)],cmap = 'inferno')\n",
    "    if is_wandb:\n",
    "            wandb.log({\"examples\": wandb.Image(fig)})\n",
    "    \n",
    "    return train_losses.avg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # sampled_images = diffusion.sample(model, n=images.shape[0])\n",
    "    # save_images(sampled_images, os.path.join(\"results\", args.run_name, f\"{epoch}.jpg\"))\n",
    "    # torch.save(model.state_dict(), os.path.join(\"models\", args.run_name, f\"ckpt.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b30d82-2a67-447e-8ba8-81ebbc959f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 122.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 1: 0.8310236911463543 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 123.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 2: 0.7340990038422065 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 123.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 3: 0.6775093975105906 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 122.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 4: 0.6309834733241941 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 124.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 5: 0.5971162178652073 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 122.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 6: 0.5707653152748822 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 122.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 7: 0.5506738746553902 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:07, 125.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 8: 0.5289284875237845 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 119.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 9: 0.5136430316824254 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 116.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 10: 0.5001053378833988 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 11: 0.49287696437137885 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 12: 0.4832145314875657 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 123.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 13: 0.4765167233905172 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 123.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 14: 0.46849952092984826 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 120.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 15: 0.46372510262621125 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 116.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 16: 0.45612215923099986 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 17: 0.46009920404209353 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 18: 0.4535931901233952 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 122.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 19: 0.452409389300075 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 123.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 20: 0.4382847818901868 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 118.54it/s]\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:22: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 21: 0.44238237055336554 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 22: 0.42962266831863216 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 118.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 23: 0.4289246535882717 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 24: 0.43512119049948406 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 122.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 25: 0.4316828267845681 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 124.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 26: 0.42737804607647223 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 119.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 27: 0.42391054053616717 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 116.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 28: 0.4146441071014094 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 29: 0.4175416376532578 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 30: 0.4237318993583927 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 31: 0.41795993578143237 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 122.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 32: 0.4118507974516086 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 120.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 33: 0.4119921484129216 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 34: 0.41081818114451274 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 118.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 35: 0.4111133321998565 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 118.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 36: 0.4035631335847746 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 122.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 37: 0.406869388450452 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 123.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 38: 0.40796283759721896 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 120.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 39: 0.40654319718601256 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 40: 0.4071296469225147 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 41: 0.40098144441116146 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 116.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 42: 0.3916761604993324 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 123.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 43: 0.3980399010384955 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 124.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 44: 0.40043685518629185 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 118.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 45: 0.3865048432253241 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 46: 0.3939932688949554 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 118.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 47: 0.3884418139128181 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 118.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 48: 0.3905378575247478 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 123.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 49: 0.3947187492517921 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 123.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 50: 0.39368359514368256 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 51: 0.3931371528443282 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 52: 0.388915110894335 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 53: 0.3913960065541229 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 116.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 54: 0.3841421642923743 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 122.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 55: 0.3798587619046855 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 123.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 56: 0.38158493277018635 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 118.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 57: 0.38594452200866325 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 58: 0.39048002963143635 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 59: 0.37720593373949934 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 60: 0.37919133659300763 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 121.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 61: 0.3823715540451732 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 123.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 62: 0.3688789417104023 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 120.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 63: 0.37272356656508715 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 64: 0.38477517943072126 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 65: 0.37260537891368556 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 118.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 66: 0.3755431868196503 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 119.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 67: 0.3712528022081871 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 124.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 68: 0.3723270951247797 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 122.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 69: 0.37501486602837475 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 118.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 70: 0.36648564004316564 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 118.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 71: 0.37616018781332466 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 117.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64)\n",
      "Epoch 72: 0.36168997656039104 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [00:08, 120.61it/s]\n"
     ]
    }
   ],
   "source": [
    "best_loss = 10000000\n",
    "train_loss_list = []\n",
    "n_epochs = 5000\n",
    "\n",
    "# if not os.path.exists(exp_path):\n",
    "#     os.mkdir(exp_path)\n",
    "# print(\"Training \", end='')\n",
    "for epoch_idx in range(n_epochs):\n",
    "    # print('=', end='')\n",
    "    \n",
    "    train_loss = train(model,diffusion,encoder,decoder,optimizer,train_data_loader,is_wandb=is_wandb)     \n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch {epoch_idx+1}: {train_loss} \")\n",
    "    if (train_loss < best_loss): \n",
    "        best_loss = train_loss\n",
    "        # print(\"Saving Best Model =======================================>\")\n",
    "        torch.save(model, f'{exp_path}/u_net_diff_best_loss.pth.tar')\n",
    "        # torch.save(cond_enc, f'{exp_path}/cond_enc_diff.pth.tar')\n",
    "    if (epoch_idx+1)%10 == 0:\n",
    "        torch.save(model, f'{exp_path}/u_net_diff_checkpoint.pth.tar')\n",
    "                       \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec11e9a-af42-4dcd-b9e2-aff1d7291207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96715009-70c7-4ec9-8553-9abe71af56ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
