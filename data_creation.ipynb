{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40704999-03ec-42fd-b19e-d3cd9b1671e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"],torch.cuda.device_count(), torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01996958-3a48-4cb6-8441-2f86671bebc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch import optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import time\n",
    "import math\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e3736b4-a564-42bb-a19f-a64347523024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string, sys, getopt\n",
    "\n",
    "alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
    "states = len(alpha_1)\n",
    "alpha_3 = ['ALA','ARG','ASN','ASP','CYS','GLN','GLU','GLY','HIS','ILE',\n",
    "           'LEU','LYS','MET','PHE','PRO','SER','THR','TRP','TYR','VAL','GAP']\n",
    "\n",
    "aa_1_N = {a:n for n,a in enumerate(alpha_1)}\n",
    "aa_3_N = {a:n for n,a in enumerate(alpha_3)}\n",
    "aa_N_1 = {n:a for n,a in enumerate(alpha_1)}\n",
    "aa_1_3 = {a:b for a,b in zip(alpha_1,alpha_3)}\n",
    "aa_3_1 = {b:a for a,b in zip(alpha_1,alpha_3)}\n",
    "\n",
    "def AA_to_N(x):\n",
    "  # [\"ARND\"] -> [[0,1,2,3]]\n",
    "  x = np.array(x);\n",
    "  if x.ndim == 0: x = x[None]\n",
    "  return [[aa_1_N.get(a, states-1) for a in y] for y in x]\n",
    "\n",
    "def N_to_AA(x):\n",
    "  # [[0,1,2,3]] -> [\"ARND\"]\n",
    "  x = np.array(x);\n",
    "  if x.ndim == 1: x = x[None]\n",
    "  return [\"\".join([aa_N_1.get(a,\"-\") for a in y]) for y in x]\n",
    "\n",
    "def parse_PDB(x, atoms=['N','CA','C'], chain=None):\n",
    "  '''\n",
    "  input:  x = PDB filename\n",
    "          atoms = atoms to extract (optional)\n",
    "  output: (length, atoms, coords=(x,y,z)), sequence\n",
    "  '''\n",
    "  xyz,seq,min_resn,max_resn = {},{},np.inf,-np.inf\n",
    "  for line in open(x,\"rb\"):\n",
    "    line = line.decode(\"utf-8\",\"ignore\").rstrip()\n",
    "\n",
    "    if line[:6] == \"HETATM\" and line[17:17+3] == \"MSE\":\n",
    "      line = line.replace(\"HETATM\",\"ATOM  \")\n",
    "      line = line.replace(\"MSE\",\"MET\")\n",
    "\n",
    "    if line[:4] == \"ATOM\":\n",
    "      ch = line[21:22]\n",
    "      if ch == chain or chain is None:\n",
    "        atom = line[12:12+4].strip()\n",
    "        resi = line[17:17+3]\n",
    "        resn = line[22:22+5].strip()\n",
    "        x,y,z = [float(line[i:(i+8)]) for i in [30,38,46]]\n",
    "\n",
    "        if resn[-1].isalpha(): resa,resn = resn[-1],int(resn[:-1])-1\n",
    "        else: resa,resn = \"\",int(resn)-1\n",
    "        if resn < min_resn: min_resn = resn\n",
    "        if resn > max_resn: max_resn = resn\n",
    "        if resn not in xyz: xyz[resn] = {}\n",
    "        if resa not in xyz[resn]: xyz[resn][resa] = {}\n",
    "        if resn not in seq: seq[resn] = {}\n",
    "        if resa not in seq[resn]: seq[resn][resa] = resi\n",
    "\n",
    "        if atom not in xyz[resn][resa]:\n",
    "          xyz[resn][resa][atom] = np.array([x,y,z])\n",
    "\n",
    "  # convert to numpy arrays, fill in missing values\n",
    "  seq_,xyz_ = [],[]\n",
    "  for resn in range(min_resn,max_resn+1):\n",
    "    if resn in seq:\n",
    "      for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k],20))\n",
    "    else: seq_.append(20)\n",
    "    if resn in xyz:\n",
    "      for k in sorted(xyz[resn]):\n",
    "        for atom in atoms:\n",
    "          if atom in xyz[resn][k]: xyz_.append(xyz[resn][k][atom])\n",
    "          else: xyz_.append(np.full(3,np.nan))\n",
    "    else:\n",
    "      for atom in atoms: xyz_.append(np.full(3,np.nan))\n",
    "  return np.array(xyz_).reshape(-1,len(atoms),3), np.array(seq_)\n",
    "\n",
    "def extend(a,b,c, L,A,D):\n",
    "  '''\n",
    "  input:  3 coords (a,b,c), (L)ength, (A)ngle, and (D)ihedral\n",
    "  output: 4th coord\n",
    "  '''\n",
    "  N = lambda x: x/np.sqrt(np.square(x).sum(-1,keepdims=True) + 1e-8)\n",
    "  bc = N(b-c)\n",
    "  n = N(np.cross(b-a, bc))\n",
    "  m = [bc,np.cross(n,bc),n]\n",
    "  d = [L*np.cos(A), L*np.sin(A)*np.cos(D), -L*np.sin(A)*np.sin(D)]\n",
    "  return c + sum([m*d for m,d in zip(m,d)])\n",
    "\n",
    "def to_len(a,b):\n",
    "  '''given coordinates a-b, return length or distance'''\n",
    "  return np.sqrt(np.sum(np.square(a-b),axis=-1))\n",
    "\n",
    "def to_len_pw(a,b=None):\n",
    "  '''given coordinates a-b return pairwise distance matrix'''\n",
    "  a_norm = np.square(a).sum(-1)\n",
    "  if b is None: b,b_norm = a,a_norm\n",
    "  else: b_norm = np.square(b).sum(-1)\n",
    "  return np.sqrt(np.abs(a_norm.reshape(-1,1) + b_norm - 2*(a@b.T)))\n",
    "\n",
    "def to_ang(a,b,c):\n",
    "  '''given coordinates a-b-c, return angle'''\n",
    "  D = lambda x,y: np.sum(x*y,axis=-1)\n",
    "  N = lambda x: x/np.sqrt(np.square(x).sum(-1,keepdims=True) + 1e-8)\n",
    "  return np.arccos(D(N(b-a),N(b-c)))\n",
    "\n",
    "def to_dih(a,b,c,d):\n",
    "  '''given coordinates a-b-c-d, return dihedral'''\n",
    "  D = lambda x,y: np.sum(x*y,axis=-1)\n",
    "  N = lambda x: x/np.sqrt(np.square(x).sum(-1,keepdims=True) + 1e-8)\n",
    "  bc = N(b-c)\n",
    "  n1 = np.cross(N(a-b),bc)\n",
    "  n2 = np.cross(bc,N(c-d))\n",
    "  return np.arctan2(D(np.cross(n1,bc),n2),D(n1,n2))\n",
    "\n",
    "def prep_input(pdb, chain=None, mask_gaps=False):\n",
    "  '''Parse PDB file and return features compatible with TrRosetta'''\n",
    "  ncac, seq = parse_PDB(pdb,[\"N\",\"CA\",\"C\"], chain=chain)\n",
    "\n",
    "  # mask gap regions\n",
    "  if mask_gaps:\n",
    "    mask = seq != 20\n",
    "    ncac, seq = ncac[mask], seq[mask]\n",
    "\n",
    "  N,CA,C = ncac[:,0], ncac[:,1], ncac[:,2]\n",
    "  CB = extend(C, N, CA, 1.522, 1.927, -2.143)\n",
    "\n",
    "  dist_ref  = to_len(CB[:,None], CB[None,:])\n",
    "  omega_ref = to_dih(CA[:,None], CB[:,None], CB[None,:], CA[None,:])\n",
    "  theta_ref = to_dih( N[:,None], CA[:,None], CB[:,None], CB[None,:])\n",
    "  phi_ref   = to_ang(CA[:,None], CB[:,None], CB[None,:])\n",
    "    \n",
    "    \n",
    "  def mtx2bins(x_ref, start, end, nbins, mask):\n",
    "    bins = np.linspace(start, end, nbins)\n",
    "    x_true = np.digitize(x_ref, bins).astype(np.uint8)\n",
    "    x_true[mask] = 0\n",
    "    return np.eye(nbins+1)[x_true][...,:-1]\n",
    "\n",
    "  p_dist  = mtx2bins(dist_ref,     2.0,  20.0, 37, mask=(dist_ref > 20))\n",
    "  p_omega = mtx2bins(omega_ref, -np.pi, np.pi, 25, mask=(p_dist[...,0]==1))\n",
    "  p_theta = mtx2bins(theta_ref, -np.pi, np.pi, 25, mask=(p_dist[...,0]==1))\n",
    "  p_phi   = mtx2bins(phi_ref,      0.0, np.pi, 13, mask=(p_dist[...,0]==1))\n",
    "  \n",
    "  feat    = {\"theta\":p_theta, \"phi\":p_phi, \"dist\":p_dist, \"omega\":p_omega}\n",
    "  \n",
    "  angles    = {\"theta_ref\":theta_ref, \"phi_ref\":phi_ref, \"omega_ref\":omega_ref}\n",
    "  #Creating binary mask for loss\n",
    "  binary_mask = np.expand_dims(np.isnan(dist_ref),-1)\n",
    "  binary_mask = (binary_mask -1)*(-1)\n",
    "\n",
    "    \n",
    "  return {\"seq\":N_to_AA(seq), \"feat\":feat, \"dist_ref\":dist_ref,\"mask\":binary_mask,'Angles_ref':angles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fad47c1-2a65-461e-acb9-6de0097996b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2oh(seq):\n",
    "  restypes = [\n",
    "      'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P',\n",
    "      'S', 'T', 'W', 'Y', 'V','-']\n",
    "  return np.eye(21)[np.array([restypes.index(x) for x in seq])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cb4da78-eff9-44ad-8389-37c54ba5c159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shared/pdb\n"
     ]
    }
   ],
   "source": [
    "%cd /home/shared/pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9c7630c-6d76-4ba5-9786-babef177bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sub_plots(rows,columns,img_list,title_list,cmap = 'inferno'):\n",
    "    fig, axs = plt.subplots(rows, columns, figsize = (columns*10,rows*10))\n",
    "    if rows == 1:\n",
    "        for i in range(len(img_list)):\n",
    "            im1 = axs[i].imshow(img_list[i],cmap=cmap)\n",
    "            axs[i].set_title(f\"{title_list[i]}\")\n",
    "            plt.colorbar(im1, ax=axs[i])#,shrink = 0.3\n",
    "    else:\n",
    "        for i in range(len(img_list)):\n",
    "            im1 = axs[i//columns][i%columns].imshow(img_list[i],cmap=cmap)\n",
    "            axs[i//columns][i%columns].set_title(f\"{title_list[i]}\")\n",
    "            plt.colorbar(im1, ax=axs[i//columns][i%columns])#,shrink = 0.3)\n",
    "    # plt.show()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef017b-6afb-4ad6-9243-cb47b165b3f4",
   "metadata": {},
   "source": [
    "## Get SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "818624e2-2d76-4457-953e-766723fcdef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_dot(v1,v2):\n",
    "    return (v1*v2).sum(axis=-1)\n",
    "\n",
    "def norm_vector(v):\n",
    "    factor = np.linalg.norm(v, axis=-1)\n",
    "    if isinstance(factor, np.ndarray):\n",
    "        v /= factor[..., np.newaxis]\n",
    "    else:\n",
    "        v /= factor\n",
    "    return v\n",
    "\n",
    "def coord(x):\n",
    "    return np.asarray(x)\n",
    "def displacement(atoms1, atoms2):\n",
    "    v1 = coord(atoms1)\n",
    "    v2 = coord(atoms2)\n",
    "    if len(v1.shape) <= len(v2.shape):\n",
    "        diff = v2 - v1\n",
    "    else:\n",
    "        diff = -(v1 - v2)\n",
    "    return diff\n",
    "def distance(atoms1, atoms2):\n",
    "    diff = displacement(atoms1, atoms2)\n",
    "    return np.sqrt(vector_dot(diff, diff))\n",
    "\n",
    "def angle(atoms1, atoms2, atoms3):\n",
    "    v1 = displacement(atoms1, atoms2)\n",
    "    v2 = displacement(atoms3, atoms2)\n",
    "    norm_vector(v1)\n",
    "    norm_vector(v2)\n",
    "    return np.arccos(vector_dot(v1,v2))\n",
    "\n",
    "def dihedral(atoms1, atoms2, atoms3, atoms4):\n",
    "    v1 = displacement(atoms1, atoms2)\n",
    "    v2 = displacement(atoms2, atoms3)\n",
    "    v3 = displacement(atoms3, atoms4)\n",
    "    norm_vector(v1)\n",
    "    norm_vector(v2)\n",
    "    norm_vector(v3)\n",
    "    \n",
    "    n1 = np.cross(v1, v2)\n",
    "    n2 = np.cross(v2, v3)\n",
    "    \n",
    "    # Calculation using atan2, to ensure the correct sign of the angle \n",
    "    x = vector_dot(n1,n2)\n",
    "    y = vector_dot(np.cross(n1,n2), v2)\n",
    "    return np.arctan2(y,x)\n",
    "\n",
    "def annotate_sse(ca_coord):\n",
    "  _radians_to_angle = 2*np.pi/360\n",
    "\n",
    "  _r_helix = ((89-12)*_radians_to_angle, (89+12)*_radians_to_angle)\n",
    "  _a_helix = ((50-20)*_radians_to_angle, (50+20)*_radians_to_angle)\n",
    "  _d2_helix = ((5.5-0.5), (5.5+0.5))\n",
    "  _d3_helix = ((5.3-0.5), (5.3+0.5))\n",
    "  _d4_helix = ((6.4-0.6), (6.4+0.6))\n",
    "\n",
    "  _r_strand = ((124-14)*_radians_to_angle, (124+14)*_radians_to_angle)\n",
    "  _a_strand = ((-180)*_radians_to_angle, (-125)*_radians_to_angle,\n",
    "              (145)*_radians_to_angle, (180)*_radians_to_angle)\n",
    "  _d2_strand = ((6.7-0.6), (6.7+0.6))\n",
    "  _d3_strand = ((9.9-0.9), (9.9+0.9))\n",
    "  _d4_strand = ((12.4-1.1), (12.4+1.1))\n",
    "\n",
    "  # Filter all CA atoms in the relevant chain.\n",
    "\n",
    "  d2i_coord = np.full(( len(ca_coord), 2, 3 ), np.nan)\n",
    "  d3i_coord = np.full(( len(ca_coord), 2, 3 ), np.nan)\n",
    "  d4i_coord = np.full(( len(ca_coord), 2, 3 ), np.nan)\n",
    "  ri_coord = np.full(( len(ca_coord), 3, 3 ), np.nan)\n",
    "  ai_coord = np.full(( len(ca_coord), 4, 3 ), np.nan)\n",
    "  \n",
    "  # The distances and angles are not defined for the entire interval,\n",
    "  # therefore the indices do not have the full range\n",
    "  # Values that are not defined are NaN\n",
    "  for i in range(1, len(ca_coord)-1):\n",
    "      d2i_coord[i] = (ca_coord[i-1], ca_coord[i+1])\n",
    "  for i in range(1, len(ca_coord)-2):\n",
    "      d3i_coord[i] = (ca_coord[i-1], ca_coord[i+2])\n",
    "  for i in range(1, len(ca_coord)-3):\n",
    "      d4i_coord[i] = (ca_coord[i-1], ca_coord[i+3])\n",
    "  for i in range(1, len(ca_coord)-1):\n",
    "      ri_coord[i] = (ca_coord[i-1], ca_coord[i], ca_coord[i+1])\n",
    "  for i in range(1, len(ca_coord)-2):\n",
    "      ai_coord[i] = (ca_coord[i-1], ca_coord[i],\n",
    "                      ca_coord[i+1], ca_coord[i+2])\n",
    "  \n",
    "  d2i = distance(d2i_coord[:,0], d2i_coord[:,1])\n",
    "  d3i = distance(d3i_coord[:,0], d3i_coord[:,1])\n",
    "  d4i = distance(d4i_coord[:,0], d4i_coord[:,1])\n",
    "  ri = angle(ri_coord[:,0], ri_coord[:,1], ri_coord[:,2])\n",
    "  ai = dihedral(ai_coord[:,0], ai_coord[:,1],\n",
    "                ai_coord[:,2], ai_coord[:,3])\n",
    "  \n",
    "  sse = np.full(len(ca_coord), \"c\", dtype=\"U1\")\n",
    "  \n",
    "  # Annotate helices\n",
    "  # Find CA that meet criteria for potential helices\n",
    "  is_pot_helix = np.zeros(len(sse), dtype=bool)\n",
    "  for i in range(len(sse)):\n",
    "      if (\n",
    "              d3i[i] >= _d3_helix[0] and d3i[i] <= _d3_helix[1]\n",
    "          and d4i[i] >= _d4_helix[0] and d4i[i] <= _d4_helix[1]\n",
    "          ) or (\n",
    "              ri[i] >= _r_helix[0] and ri[i] <= _r_helix[1]\n",
    "          and ai[i] >= _a_helix[0] and ai[i] <= _a_helix[1]\n",
    "          ):\n",
    "              is_pot_helix[i] = True\n",
    "  # Real helices are 5 consecutive helix elements\n",
    "  is_helix = np.zeros(len(sse), dtype=bool)\n",
    "  counter = 0\n",
    "  for i in range(len(sse)):\n",
    "      if is_pot_helix[i]:\n",
    "          counter += 1\n",
    "      else:\n",
    "          if counter >= 5:\n",
    "              is_helix[i-counter : i] = True\n",
    "          counter = 0\n",
    "  # Extend the helices by one at each end if CA meets extension criteria\n",
    "  i = 0\n",
    "  while i < len(sse):\n",
    "      if is_helix[i]:\n",
    "          sse[i] = \"a\"\n",
    "          if (\n",
    "              d3i[i-1] >= _d3_helix[0] and d3i[i-1] <= _d3_helix[1]\n",
    "              ) or (\n",
    "              ri[i-1] >= _r_helix[0] and ri[i-1] <= _r_helix[1]\n",
    "              ):\n",
    "                  sse[i-1] = \"a\"\n",
    "          sse[i] = \"a\"\n",
    "          if (\n",
    "              d3i[i+1] >= _d3_helix[0] and d3i[i+1] <= _d3_helix[1]\n",
    "              ) or (\n",
    "              ri[i+1] >= _r_helix[0] and ri[i+1] <= _r_helix[1]\n",
    "              ):\n",
    "                  sse[i+1] = \"a\"\n",
    "      i += 1\n",
    "  \n",
    "  # Annotate sheets\n",
    "  # Find CA that meet criteria for potential strands\n",
    "  is_pot_strand = np.zeros(len(sse), dtype=bool)\n",
    "  for i in range(len(sse)):\n",
    "      if (    d2i[i] >= _d2_strand[0] and d2i[i] <= _d2_strand[1]\n",
    "          and d3i[i] >= _d3_strand[0] and d3i[i] <= _d3_strand[1]\n",
    "          and d4i[i] >= _d4_strand[0] and d4i[i] <= _d4_strand[1]\n",
    "          ) or (\n",
    "              ri[i] >= _r_strand[0] and ri[i] <= _r_strand[1]\n",
    "          and (   (ai[i] >= _a_strand[0] and ai[i] <= _a_strand[1])\n",
    "                or (ai[i] >= _a_strand[2] and ai[i] <= _a_strand[3]))\n",
    "          ):\n",
    "              is_pot_strand[i] = True\n",
    "  # Real strands are 5 consecutive strand elements,\n",
    "  # or shorter fragments of at least 3 consecutive strand residues,\n",
    "  # if they are in hydrogen bond proximity to 5 other residues\n",
    "  pot_strand_coord = ca_coord[is_pot_strand]\n",
    "  is_strand = np.zeros(len(sse), dtype=bool)\n",
    "  counter = 0\n",
    "  contacts = 0\n",
    "  for i in range(len(sse)):\n",
    "      if is_pot_strand[i]:\n",
    "          counter += 1\n",
    "          coord = ca_coord[i]\n",
    "          for strand_coord in ca_coord:\n",
    "              dist = distance(coord, strand_coord)\n",
    "              if dist >= 4.2 and dist <= 5.2:\n",
    "                  contacts += 1\n",
    "      else:\n",
    "          if counter >= 4:\n",
    "              is_strand[i-counter : i] = True\n",
    "          elif counter == 3 and contacts >= 5:\n",
    "              is_strand[i-counter : i] = True\n",
    "          counter = 0\n",
    "          contacts = 0\n",
    "  # Extend the strands by one at each end if CA meets extension criteria\n",
    "  i = 0\n",
    "  while i < len(sse):\n",
    "      if is_strand[i]:\n",
    "          sse[i] = \"b\"\n",
    "          if d3i[i-1] >= _d3_strand[0] and d3i[i-1] <= _d3_strand[1]:\n",
    "              sse[i-1] = \"b\"\n",
    "          sse[i] = \"b\"\n",
    "          if d3i[i+1] >= _d3_strand[0] and d3i[i+1] <= _d3_strand[1]:\n",
    "              sse[i+1] = \"b\"\n",
    "      i += 1\n",
    "  \n",
    "  return sse\n",
    "\n",
    "def get_ca(pdb_filename, chain=\"A\"):\n",
    "  '''\n",
    "  input:  x = PDB filename\n",
    "          atoms = atoms to extract (optional)\n",
    "  output: (length, coords=(x,y,z))\n",
    "  '''\n",
    "  n, xyz = None, []\n",
    "  seen = []\n",
    "  seq = []\n",
    "  for line in open(pdb_filename,\"r\"):\n",
    "    line = line.rstrip()\n",
    "    if line[:6] == \"HETATM\" and line[17:17+3] == \"MSE\":\n",
    "      line = line.replace(\"HETATM\",\"ATOM  \")\n",
    "      line = line.replace(\"MSE\",\"MET\")\n",
    "    if line[:4] == \"ATOM\":\n",
    "      atom = line[12:12+4].strip()\n",
    "      if atom == \"CA\":\n",
    "        resn = int(line[22:22+5])\n",
    "        resi = line[17:17+3]\n",
    "        ch = line[21:22]\n",
    "        if ch == chain and resn not in seen:\n",
    "          x = float(line[30:30+8])\n",
    "          y = float(line[38:38+8])\n",
    "          z = float(line[46:46+8])\n",
    "          # extract coordiantes\n",
    "          if n is None:\n",
    "            n = resn\n",
    "          while n < resn:\n",
    "            xyz.append([np.nan,np.nan,np.nan])\n",
    "            seen.append(n)\n",
    "            seq.append(\"NAN\")\n",
    "            n += 1\n",
    "          if n == resn:\n",
    "            xyz.append([x,y,z])\n",
    "            seen.append(n)\n",
    "            seq.append(resi)\n",
    "            n += 1\n",
    "  return np.array(xyz), np.array(seq)\n",
    "\n",
    "\n",
    "def onehot_encode(pdb_file):\n",
    "    ca_coords, seq = get_ca(pdb_file,chain=\"A\")\n",
    "    t_str_list = annotate_sse(ca_coords)\n",
    "    # print(t_str_list)\n",
    "    int_list =[]\n",
    "    int_list = np.array(t_str_list)\n",
    "    \n",
    "    int_list[int_list=='a'] = 0\n",
    "    int_list[int_list=='b'] = 1\n",
    "    int_list[int_list=='c'] = 2\n",
    "    # print(int_list)\n",
    "    hotenc = F.one_hot(torch.from_numpy(int_list.astype('int')), num_classes=3).moveaxis(-1,0)#torch.from_numpy(np.array(int_list))#\n",
    "    # print(hotenc)\n",
    "    sse_2d = np.ones((9,hotenc.shape[-1],hotenc.shape[-1]))\n",
    "    k=0\n",
    "    for i in range(hotenc.shape[0]):\n",
    "        # print(f'i {i}')\n",
    "        for j in range(hotenc.shape[0]):\n",
    "            # print(f'j {j}')\n",
    "            sse_2d[k,:,:]=(hotenc[i,:].unsqueeze(1)*hotenc[j,:].unsqueeze(1).T)\n",
    "            k += 1\n",
    "    return hotenc,torch.from_numpy(sse_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb0c87-e852-4590-a2e3-b825d0762676",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7cfd5dfc-9c5f-460a-b1db-541fdf8e7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exception = ['/home/shared/pdb/3gbn_1_C.pdb','/home/shared/pdb/3fqd_1_A.pdb','/home/shared/pdb/3e6p_1_B.pdb','/home/shared/pdb/1acx_1_A.pdb', '/home/shared/pdb/1aye,_1_A.pdb', '/home/shared/pdb/1b5f_1_C.pdb', '/home/shared/pdb/1b5f_1_D.pdb', '/home/shared/pdb/1bbr_1_C.pdb', '/home/shared/pdb/1bcs_1_B.pdb', '/home/shared/pdb/1bwv_1_E.pdb', '/home/shared/pdb/1deu_1_A.pdb', '/home/shared/pdb/1dki_1_A.pdb', '/home/shared/pdb/1dle_1_B.pdb', '/home/shared/pdb/1eq9_1_B.pdb', '/home/shared/pdb/1eso_1_A.pdb', '/home/shared/pdb/1et6_1_A.pdb', '/home/shared/pdb/1fo0_1_A.pdb', '/home/shared/pdb/1fo0_1_B.pdb', '/home/shared/pdb/1gpl_1_A.pdb', '/home/shared/pdb/1hia_1_A.pdb', '/home/shared/pdb/1hia_1_B.pdb', '/home/shared/pdb/1li1_1_F.pdb', '/home/shared/pdb/1pg7_1_C.pdb', '/home/shared/pdb/1pvt_1_A.pdb', '/home/shared/pdb/1pyt_1_A.pdb', '/home/shared/pdb/1qdm_1_A.pdb', '/home/shared/pdb/1ro5_1_A.pdb', '/home/shared/pdb/1sgc_1_A.pdb', '/home/shared/pdb/1un2_1_A.pdb', '/home/shared/pdb/1wht_1_A.pdb', '/home/shared/pdb/1xso_1_B.pdb', '/home/shared/pdb/1yg9_1_A.pdb', '/home/shared/pdb/2b5t_1_A.pdb', '/home/shared/pdb/2fd6_1_D.pdb', '/home/shared/pdb/2fh5_1_A.pdb', '/home/shared/pdb/2hnt_1_A.pdb', '/home/shared/pdb/2hnt_1_B.pdb', '/home/shared/pdb/2ocv_1_B.pdb','/home/shared/pdb/2zfn_1_A.pdb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154a6bc-8c92-4eb2-a5ec-8085b4ca5cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15051\n",
      "=(210, 210) (210, 210) (210, 210) (210, 210) (210, 210, 1) torch.Size([3, 210]) ['MPPYTVVYFPVRGRCAALRMLLADQGQSWKEEVVTVETWQEGSLKASCLYGQLPKFQDGDLTLYQSNTILRHLGRTLGLYGKDQQEAALVDMVNDGVEDLRCKYISLIYTNYEAGKDDYVKALPGQLKPFETLLSQNQGGKTFIVGDQISFADYNLLDLLLIHEVLAPGCLDAFPLLSAYVGRLSARPKLKAFLASPEYVNLPINGNGKQ']\n",
      "======="
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "file_list = glob.glob(\"/home/shared/pdb/*.pdb\")\n",
    "file_list.sort()\n",
    "print(len(file_list))\n",
    "\n",
    "# file_list= file_list[6637:]\n",
    "\n",
    "save_path = \"/home/jupyter-jathurshan/Protein_extracted_data\"\n",
    "count = 0\n",
    "print(\"=\",end = '')\n",
    "c = 0\n",
    "for pdb_file in file_list:\n",
    "    # print(pdb_file)\n",
    "    if pdb_file in exception:\n",
    "        continue\n",
    "    try: \n",
    "        # Get SSE\n",
    "        sse,_ = onehot_encode(pdb_file)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    X = prep_input(pdb_file)\n",
    "    \n",
    "    dist_ref = X['dist_ref']\n",
    "    seq = X['seq'][0]\n",
    "    theta_ref = X['Angles_ref']['theta_ref']\n",
    "    phi_ref = X['Angles_ref']['phi_ref']\n",
    "    omega_ref = X['Angles_ref']['omega_ref']\n",
    "    mask = X[\"mask\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if c==0:\n",
    "        print(dist_ref.shape,theta_ref.shape,phi_ref.shape,omega_ref.shape,mask.shape,sse.shape,np.array([seq]))\n",
    "        plot_sub_plots(1,6,[dist_ref,theta_ref,phi_ref,omega_ref,mask,sse],\n",
    "                       ['dist_ref','theta_ref','phi_ref','omega_ref','mask','SSE'],cmap = 'inferno')\n",
    "        c+=1\n",
    "    \n",
    "    \n",
    "    file_name = pdb_file.split('/')[-1].split('.')[0]\n",
    "    # print(f'{save_path}/{file_name}.h5')\n",
    "    # break\n",
    "    with h5py.File(f'{save_path}/{file_name}.h5', \"w\") as hf:\n",
    "        hf.create_dataset('dist_ref', data=dist_ref)\n",
    "        hf.create_dataset('theta_ref', data=theta_ref)\n",
    "        hf.create_dataset('phi_ref', data=phi_ref)\n",
    "        hf.create_dataset('omega_ref', data=omega_ref)\n",
    "        hf.create_dataset('mask', data=mask)\n",
    "        hf.create_dataset('sse', data=sse)\n",
    "        hf.create_dataset('seq', data=seq)\n",
    "        # hf.create_dataset('Pad', data=4-sample.shape[-1]%4)\n",
    "    hf.close()\n",
    "    # print(sample.detach().cpu().squeeze().numpy().shape,mask.detach().cpu().squeeze().numpy().shape)#,pad.shape)\n",
    "    # break\n",
    "    if (count+1)%1000 == 0:\n",
    "        print(\"=\",end = '')\n",
    "    count+=1\n",
    "# sample_list = np.array(sample_list)\n",
    "# mask_list = np.array(mask_list)\n",
    "# pad_list = np.array(pad_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a481a047-3397-41ff-bb12-34d90828d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15051\n",
    "file_list = glob.glob(\"/home/jupyter-jathurshan/Protein_extracted_data/*.h5\")\n",
    "file_list.sort()\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab49b6-6373-4359-949c-724de2be8038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
